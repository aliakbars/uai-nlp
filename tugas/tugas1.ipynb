{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c8c3b3",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Tugas 1: Regular Expressions & Model Bahasa N-gram\n",
    "\n",
    "### Mekanisme\n",
    "\n",
    "Anda hanya diwajibkan untuk mengumpulkan file ini saja ke uploader yang disediakan di https://elearning.uai.ac.id/. Ganti nama file ini saat pengumpulan menjadi **tugas1_NIM.ipynb**.\n",
    "\n",
    "**Keterlambatan**: Pengumpulan tugas yang melebihi tenggat yang telah ditentukan tidak akan diterima. Keterlambatan akan berakibat pada nilai nol untuk tugas ini.\n",
    "\n",
    "**Kolaborasi**: Anda diperbolehkan untuk berdiskusi dengan teman Anda, tetapi dilarang keras menyalin kode maupun tulisan dari teman Anda.\n",
    "\n",
    "### Petunjuk\n",
    "\n",
    "Pastikan jawaban Anda singkat, padat, dan jelas. Mayoritas pertanyaan yang diberikan dapat dijawab dalam 3-4 kalimat saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2bd648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe8d33",
   "metadata": {},
   "source": [
    "## 1. Regular Expressions (5 poin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08817304",
   "metadata": {},
   "source": [
    "### Soal 1.1 (2 poin)\n",
    "\n",
    "Cari pola regular expression yang dapat mencocokkan semua elemen di dalam `words_a`, tetapi tidak cocok dengan apa pun di dalam `words_b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_a = [\n",
    "    \"membacakan\",\n",
    "    \"menuliskan\",\n",
    "    \"melihatkan\",\n",
    "    \"mendengarkan\",\n",
    "    \"mengajarkan\",\n",
    "    \"menarikan\",\n",
    "    \"menyanyikan\",\n",
    "    \"memasakkan\",\n",
    "    \"mencucikan\",\n",
    "    \"membelikan\",\n",
    "    \"menjualkan\",\n",
    "    \"memberikan\",\n",
    "]\n",
    "\n",
    "words_b = [\n",
    "    \"rumah\",\n",
    "    \"meja\",\n",
    "    \"kursi\",\n",
    "    \"ikan\",\n",
    "    \"semen\",\n",
    "    \"ramen\",\n",
    "    \"akan\",\n",
    "    \"bukan\",\n",
    "    \"mental\",\n",
    "]\n",
    "\n",
    "pattern = \"\" # Jawaban Anda di sini\n",
    "assert pd.Series(words_a).str.contains(pattern).all()\n",
    "assert not pd.Series(words_b).str.match(pattern).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945567fa",
   "metadata": {},
   "source": [
    "### Soal 1.2 (3 poin)\n",
    "\n",
    "Cari pola regular expression yang dapat mencocokkan semua elemen di dalam `buah_a`, tetapi tidak cocok dengan apa pun di dalam `buah_b`. Anda hanya boleh menggunakan maksimal 6 karakter untuk pola yang dihasilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "buah_a = [\n",
    "    \"pisang\",\n",
    "    \"mangga\",\n",
    "    \"rambutan\",\n",
    "    \"durian\",\n",
    "    \"salak\",\n",
    "    \"duku\",\n",
    "    \"kelapa\",\n",
    "    \"sirsak\",\n",
    "    \"belimbing\",\n",
    "    \"manggis\",\n",
    "]\n",
    "\n",
    "buah_b = [\n",
    "    \"pir\",\n",
    "    \"stroberi\",\n",
    "    \"ceri\",\n",
    "    \"kiwi\",\n",
    "    \"leci\",\n",
    "    \"persik\",\n",
    "]\n",
    "\n",
    "pattern = \"\" # Jawaban Anda di sini\n",
    "assert len(pattern) <= 6\n",
    "assert pd.Series(buah_a).str.contains(pattern).all()\n",
    "assert not pd.Series(buah_b).str.contains(pattern).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2482f3",
   "metadata": {},
   "source": [
    "## 2. Model Bahasa N-gram (15 poin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01172ef2",
   "metadata": {},
   "source": [
    "### Deskripsi Dataset\n",
    "\n",
    "Dataset yang Anda akan gunakan dalam tugas ini adalah [Indonesian News Corpora 300K](https://wortschatz.uni-leipzig.de/en/download/Indonesian#ind_news_2024) tahun 2024 dari Leipzig Corpora Collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/aliakbars/uai-nlp/refs/heads/main/datasets/ind_news_2024_300K-sentences.txt\",\n",
    "    sep=\"\\\\t\",\n",
    "    names=[\"index\", \"text\"],\n",
    ")\n",
    "del sentences[\"index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e18a4",
   "metadata": {},
   "source": [
    "### Soal 2.1 (2 poin)\n",
    "\n",
    "Bagilah dataset menjadi data latih dan data uji dengan rasio 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e423be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = ... # Jawaban Anda di sini\n",
    "\n",
    "assert len(train) == 240_000\n",
    "assert len(test) == 60_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e3f971",
   "metadata": {},
   "source": [
    "### Soal 2.2 (2 poin)\n",
    "\n",
    "Buatlah tabel `unigram_df` yang menghasilkan **unigram** dari data latih yang telah dihasilkan di atas. Gunakan [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) untuk proses tokenisasi dan menghasilkan unigramnya, serta pola token default `'(?u)\\\\b\\\\w\\\\w+\\\\b'`.\n",
    "\n",
    "Contoh hasil tabel:\n",
    "| word      |   freq |\n",
    "|:----------|-------:|\n",
    "| diketahui |   2654 |\n",
    "| layanan   |   2015 |\n",
    "| maju      |   1386 |\n",
    "| aksi      |   1707 |\n",
    "| januari   |   1316 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Jawaban Anda di sini\n",
    "\n",
    "assert [\"word\", \"freq\"] == unigram_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961fdae1",
   "metadata": {},
   "source": [
    "### Soal 2.3 (3 poin)\n",
    "\n",
    "Buatlah tabel `bigram_df` yang menghasilkan **bigram** dari data latih yang telah dihasilkan di atas. Gunakan [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) untuk proses tokenisasi dan menghasilkan bigram, serta pola token default `'(?u)\\\\b\\\\w\\\\w+\\\\b'`. Tambahkan `ooo` sebagai _start token_ dan `zzz` sebagai _end token_.\n",
    "\n",
    "Contoh hasil tabel:\n",
    "| word          | next_word   |   freq |\n",
    "|:--------------|:------------|-------:|\n",
    "| akan          | ada         |    461 |\n",
    "| sebagai       | bentuk      |    365 |\n",
    "| dua           | orang       |    363 |\n",
    "| internasional | zzz         |    385 |\n",
    "| kasus         | ini         |    535 |\n",
    "| kami          | berharap    |    379 |\n",
    "| informasi     | yang        |    398 |\n",
    "| yang          | kita        |    465 |\n",
    "| pada          | musim       |    325 |\n",
    "| tahun         | zzz         |   1060 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawaban Anda di sini\n",
    "\n",
    "assert [\"word\", \"next_word\", \"freq\"] == bigram_df.columns.to_list()\n",
    "assert \"ooo\" in bigram_df[\"word\"].to_list()\n",
    "assert \"zzz\" in bigram_df[\"next_word\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e915dc",
   "metadata": {},
   "source": [
    "### Soal 2.4 (5 poin)\n",
    "\n",
    "Implementasikan kode yang menghasilkan array berisi skor (*log probability*) jika diberikan sebuah kalimat. Petunjuk implementasi:\n",
    "1. Gunakan tabel unigram dan bigram yang telah dihasilkan di soal sebelumnya.\n",
    "1. Gunakan metode Stupid backoff yang menggunakan parameter `alpha` untuk mengatasi kasus bigram yang tidak ditemukan.\n",
    "1. Gunakan metode Laplace smoothing untuk menangani kasus unigram yang tidak ditemukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5fa917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel:\n",
    "    def __init__(\n",
    "        self, unigram_df: pd.DataFrame, bigram_df: pd.DataFrame, alpha: float = 0.4\n",
    "    ):\n",
    "        self.unigram_df = unigram_df\n",
    "        self.bigram_df = bigram_df\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def score_unigram(self, word: str) -> float:\n",
    "        pass  # Jawaban Anda di sini\n",
    "\n",
    "    def score(self, word: str, prev_word: str) -> float:\n",
    "        pass  # Jawaban Anda di sini\n",
    "\n",
    "    def sentence_score(self, sentence: str, n: int = 2) -> np.ndarray:\n",
    "        if n == 2:\n",
    "            pass  # Jawaban Anda di sini\n",
    "        elif n == 1:\n",
    "            pass  # Jawaban Anda di sini\n",
    "        else:\n",
    "            raise NotImplemented(\"Saat ini hanya bisa untuk n=1 atau n=2\")\n",
    "\n",
    "\n",
    "bm = BigramModel(unigram_df, bigram_df, alpha=0.4)\n",
    "assert bm.score_unigram(\"qqq\") > bm.score(\"qqq\", \"xxx\")\n",
    "assert bm.score(\"qqq\", \"xxx\") == np.log(\n",
    "    0.4 * 1 / (unigram_df.freq.sum() + len(unigram_df))\n",
    ")\n",
    "assert bm.score(\"mana\", \"di\") <= 0\n",
    "assert bm.score(\"mungkin\", \"tidak\") > bm.score(\"qqq\", \"xxx\")\n",
    "assert bm.score(\"satu\", \"salah\") > bm.score(\"tangkap\", \"salah\")\n",
    "assert (bm.sentence_score(\"salah satu\") <= 0).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f2b476",
   "metadata": {},
   "source": [
    "### Soal 2.5.a (2 poin)\n",
    "\n",
    "Implementasikan fungsi untuk menghitung perplexity dalam logaritma. Fungsi ini hanya menerima masukan berupa array berisi $\\log P(w_i)$.\n",
    "\n",
    "$$\n",
    "PP(W) = \\sqrt[N]{\\frac{1}{\\prod_{i=1}^N P(w_i)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(log_probs: np.ndarray):\n",
    "    pass  # Jawaban Anda di sini\n",
    "\n",
    "assert perplexity(np.array([0, 0, 0])) == 1\n",
    "assert perplexity(np.array([-10, -20])) == np.exp(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a33d9",
   "metadata": {},
   "source": [
    "### Soal 2.5.b (1 poin)\n",
    "\n",
    "Berdasarkan kalimat contoh yang diberikan, periksa dan pastikan bahwa perplexity dari `BigramModel` lebih kecil daripada model unigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"pengakuan tersebut diungkapkan dalam wawancara dengan media\"\n",
    "\n",
    "# Jawaban Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f122c9",
   "metadata": {},
   "source": [
    "### Soal 2.6 (3 poin)\n",
    "\n",
    "Ambil 30 sampel dari data uji. Hitunglah nilai rata-rata berbobot (_weighted average_) perplexity per kalimat pada data uji dengan menggunakan jumlah kata per kalimat sebagai bobotnya.\n",
    "\n",
    "Pastikan bahwa:\n",
    "1. Metode tokenisasi dan preprocessing yang dilakukan sama dengan soal 2.2 dan 2.3.\n",
    "1. Nilai perplexity dihitung untuk model unigram dan bigram dengan backoff.\n",
    "\n",
    "_Petunjuk: Gunakan metode `.findall()`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e803681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jawaban Anda di sini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa046e",
   "metadata": {},
   "source": [
    "### Soal 2.7 (2 poin)\n",
    "\n",
    "Berikan kesimpulan dari analisis yang sudah dilakukan pada bagian kedua dari tugas ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5576ff95",
   "metadata": {},
   "source": [
    "*Jawaban Anda di sini*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
